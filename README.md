# Bat Orientation Calls

The Bat Orientation Calls project focuses on classifying bat types using spectrograms in image format as input. Employing both a decision tree classifier and a convolutional neural network (CNN), our approach involves a systematic workflow detailed in this Jupyter notebook.

The initial stage involves loading and preprocessing the spectrogram images along with their corresponding labels. Spectrograms, visual representations of sound, exhibit the frequency content of an audio signal over time and serve as input data for classification. Ensuring the images are in a suitable format, we proceed to explore the data, gaining insights into its characteristics and distributions before venturing into modeling.

Setting up a decision tree classifier follows, utilizing a tree-like model to make decisions based on features extracted from the spectrogram images. The performance of the decision tree classifier is then scrutinized, analyzing metrics such as accuracy, precision, recall, and F1 score. Recognizing its limitations, we experiment with techniques like pruning, random forests, Bagging, AdaBoost, and Gradient Boosting to enhance generalization.

Transitioning to a CNN model, specifically designed for image classification, we train it on the spectrogram images to automatically learn and extract features, catering to the complexity of bat type classification. The CNN's outstanding performance is evaluated on the test data, surpassing the decision tree classifier. Visualizing learning curves aids in understanding the model's training process, while strategies like early stopping and dropout mitigate overfitting.

Subsequently, we compare the results of the decision tree classifier and the CNN model, providing insights into the effectiveness of traditional machine learning and deep learning in the context of bat orientation calls classification. This comprehensive analysis aims to explore and compare the performance of diverse machine learning approaches without revealing specific model results.