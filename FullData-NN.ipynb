{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(images_paths, labels_paths, valid_labels):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    no_label_counter = 0\n",
    "    unidentified_counter = 0\n",
    "\n",
    "    for images_path, labels_path in zip(images_paths, labels_paths):\n",
    "\n",
    "        # Load labels from csv file\n",
    "        labels_df = pd.read_csv(labels_path, sep=';')\n",
    "        labels_df['Filename'] = [file[:-3] + 'png' for file in labels_df['Filename']]\n",
    "\n",
    "        for filename in os.listdir(images_path):\n",
    "            # Load the image using PIL\n",
    "            img_path = os.path.join(images_path, filename)\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            # Crop the image to the size of the spectrogram\n",
    "            left, upper, right, lower = 55, 36, 389, 252\n",
    "            img = img.crop((left, upper, right, lower))\n",
    "\n",
    "            # Convert image to numpy array and normalize\n",
    "            img_array = np.array(img)[:, :, :3] / 255.0\n",
    "\n",
    "            # Extract class label from the CSV file based on the image filename\n",
    "            label_row = labels_df.loc[labels_df['Filename'] == filename]\n",
    "            \n",
    "            if label_row.empty:\n",
    "                no_label_counter += 1\n",
    "                continue\n",
    "\n",
    "            label = label_row['Species'].values[0]\n",
    "\n",
    "            if label not in valid_labels:\n",
    "                unidentified_counter += 1\n",
    "                continue\n",
    "                \n",
    "            labels.append(label)\n",
    "            images.append(img_array)\n",
    "                \n",
    "\n",
    "    if no_label_counter:\n",
    "        print(f'Label not found for {no_label_counter} images : Images will not be used.')\n",
    "    if unidentified_counter:\n",
    "        print(f'Bat unidentified for {unidentified_counter} images : Images will not be used.')\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folders = ['./Data/dataset1', './Data/dataset2', './Data/dataset3']\n",
    "labels_paths = ['./Data/dataset1_classified.csv', './Data/dataset2_classified.csv', './Data/dataset3_classified.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the valid labels\n",
    "valid_labels = set()\n",
    "for labels_path in labels_paths:\n",
    "    labels_df = pd.read_csv(labels_path, sep=';')\n",
    "    valid_labels = valid_labels.union(set(labels_df['Species'].values))\n",
    "\n",
    "print(f'Valid labels: {valid_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid labels if they exist\n",
    "invalid_labels = ['Fledermaus nicht bestimmbar', 'Schwarzbild']\n",
    "valid_labels = [label for label in valid_labels if label not in invalid_labels]\n",
    "\n",
    "# Remove non-alphabetical labels\n",
    "valid_labels = [label for label in valid_labels if label.isalpha()]\n",
    "\n",
    "print(f'Valid labels: {valid_labels}')\n",
    "print(f'Number of valid labels: {len(valid_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_images(images_folders, labels_paths, valid_labels)\n",
    "print('Images shape: ', images.shape)\n",
    "print('Labels shape: ', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "images_flattened = images.reshape(images.shape[0], -1)\n",
    "\n",
    "# Split the data for FFNN\n",
    "X_train_FFNN, X_test_FFNN, y_train_FFNN, y_test_FFNN = train_test_split(images_flattened, encoded_labels, test_size=0.3, random_state=42)\n",
    "X_train_FFNN, X_val_FFNN, y_train_FFNN, y_val_FFNN = train_test_split(X_train_FFNN, y_train_FFNN, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data for CNN\n",
    "X_train_CNN, X_test_CNN, y_train_CNN, y_test_CNN = train_test_split(images, encoded_labels, test_size=0.3, random_state=42)\n",
    "X_train_CNN, X_val_CNN, y_train_CNN, y_val_CNN = train_test_split(X_train_CNN, y_train_CNN, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels for FFNN\n",
    "y_train_FFNN = to_categorical(y_train_FFNN)\n",
    "y_val_FFNN = to_categorical(y_val_FFNN)\n",
    "y_test_FFNN = to_categorical(y_test_FFNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights to handle class imbalance\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                  classes=np.unique(encoded_labels),\n",
    "                                                  y=encoded_labels)\n",
    "\n",
    "# Convert class weights to a dictionary\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Inverse transform the encoded labels to get the original classes\n",
    "original_classes = label_encoder.inverse_transform(np.unique(encoded_labels))\n",
    "\n",
    "for c, weight in class_weights_dict.items():\n",
    "    original_class = original_classes[c]\n",
    "    print(f'{original_class}: {weight}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define plot callback\n",
    "class PlotInfo(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.accuracy = []\n",
    "        self.val_accuracy = []\n",
    "\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_loss_epoch = 1\n",
    "        self.best_val_accuracy = 0\n",
    "        self.best_val_accuracy_epoch = 1\n",
    "\n",
    "        self.epoch = 1\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.epoch)\n",
    "\n",
    "        self.losses.append(logs.get('loss', 0))\n",
    "        self.val_losses.append(logs.get('val_loss', 0))\n",
    "        self.accuracy.append(logs.get('accuracy', 0))\n",
    "        self.val_accuracy.append(logs.get('val_accuracy', 0))\n",
    "\n",
    "        # Check if current val_loss is the best so far\n",
    "        if logs.get('val_loss') < self.best_val_loss:\n",
    "            self.best_val_loss = logs.get('val_loss')\n",
    "            self.best_val_loss_epoch = self.epoch\n",
    "\n",
    "        # Check if current val_accuracy is the best so far\n",
    "        if logs.get('val_accuracy') > self.best_val_accuracy:\n",
    "            self.best_val_accuracy = logs.get('val_accuracy')\n",
    "            self.best_val_accuracy_epoch = self.epoch\n",
    "\n",
    "        self.epoch += 1\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "        # Subplot for loss\n",
    "        ax1.plot(self.x, self.losses, label=\"loss\")\n",
    "        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        ax1.scatter(self.best_val_loss_epoch, self.best_val_loss, marker='o', color='red', label=f'best val_loss ({self.best_val_loss:.3f})')\n",
    "        ax1.set_xlabel('epoch')\n",
    "        ax1.set_ylabel('loss')\n",
    "        ax1.legend()\n",
    "\n",
    "        # Subplot for accuracy\n",
    "        ax2.plot(self.x, self.accuracy, label=\"accuracy\")\n",
    "        ax2.plot(self.x, self.val_accuracy, label=\"val_accuracy\")\n",
    "        ax2.scatter(self.best_val_accuracy_epoch, self.best_val_accuracy, marker='o', color='green', label=f'best val_accuracy ({self.best_val_accuracy:.3f})')\n",
    "        ax2.set_xlabel('epoch')\n",
    "        ax2.set_ylabel('accuracy')\n",
    "        ax2.legend()\n",
    "\n",
    "        fig.suptitle(f'Epoch {self.epoch - 1}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_info_FFNN = PlotInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFNN_model = Sequential()\n",
    "\n",
    "FFNN_model.add(Dense(128, input_dim=X_train_FFNN.shape[1], activation='relu'))\n",
    "FFNN_model.add(BatchNormalization())\n",
    "FFNN_model.add(Dropout(0.5))\n",
    "\n",
    "FFNN_model.add(Dense(64, activation='relu'))\n",
    "FFNN_model.add(BatchNormalization())\n",
    "FFNN_model.add(Dropout(0.5))\n",
    "\n",
    "FFNN_model.add(Dense(32, activation='relu'))\n",
    "FFNN_model.add(BatchNormalization())\n",
    "FFNN_model.add(Dropout(0.5))\n",
    "\n",
    "FFNN_model.add(Dense(y_train_FFNN.shape[1], activation='softmax'))\n",
    "\n",
    "FFNN_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history_FFNN = FFNN_model.fit(X_train_FFNN, y_train_FFNN,\n",
    "                              epochs=50, batch_size=32,\n",
    "                              validation_data=(X_val_FFNN, y_val_FFNN),\n",
    "                              class_weight=class_weights_dict,\n",
    "                              callbacks=[early_stopping, plot_info_FFNN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred_FFNN = FFNN_model.predict(X_test_FFNN)\n",
    "loss, accuracy = FFNN_model.evaluate(X_test_FFNN, y_test_FFNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert one-hot encoded y_test_FFNN and y_pred_FFNN back to label encoded form\n",
    "y_test_FFNN_label_encoded = np.argmax(y_test_FFNN, axis=1)\n",
    "y_pred_FFNN_label_encoded = np.argmax(y_pred_FFNN, axis=1)\n",
    "\n",
    "# Extract unique classes present in the test dataset\n",
    "unique_classes_test_FFNN = np.unique(y_test_FFNN_label_encoded)\n",
    "\n",
    "# Convert encoded labels back to original classes\n",
    "target_classes_FFNN = label_encoder.inverse_transform(unique_classes_test_FFNN)\n",
    "\n",
    "# Generate confusion matrix\n",
    "confusion_m_FFNN = confusion_matrix(y_test_FFNN_label_encoded, y_pred_FFNN_label_encoded)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(confusion_m_FFNN, annot=True, fmt='d', cmap='Blues', xticklabels=target_classes_FFNN, yticklabels=target_classes_FFNN)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "report_FFNN = classification_report(y_test_FFNN_label_encoded, y_pred_FFNN_label_encoded, target_names=target_classes_FFNN, zero_division=1, output_dict=True)\n",
    "print(classification_report(y_test_FFNN_label_encoded, y_pred_FFNN_label_encoded, target_names=target_classes_FFNN, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation using ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range = 0.025,\n",
    "    height_shift_range = 0.015,\n",
    "    channel_shift_range= 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate augmented images\n",
    "augmented_images = datagen.flow(X_train_CNN, batch_size=1, shuffle=False)\n",
    "\n",
    "# Plot original and augmented images\n",
    "num_samples = 3\n",
    "fig, axes = plt.subplots(num_samples, 2, figsize=(5, 6))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Original Image\n",
    "    original_image = X_train_CNN[i]\n",
    "    axes[i, 0].imshow(original_image)\n",
    "    axes[i, 0].set_title('Original Image')\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    # Augmented Image\n",
    "    augmented_image = augmented_images.next()[0]\n",
    "    axes[i, 1].imshow(augmented_image)\n",
    "    axes[i, 1].set_title('Augmented Image')\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = models.Sequential()\n",
    "\n",
    "CNN_model.add(layers.Conv2D(48, (3, 3), activation='relu', input_shape=(216, 334, 3)))\n",
    "CNN_model.add(layers.Dropout(0.05))\n",
    "CNN_model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "CNN_model.add(layers.Conv2D(96, (3, 3), activation='relu'))\n",
    "CNN_model.add(layers.Dropout(0.1))\n",
    "CNN_model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "CNN_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "CNN_model.add(layers.Dropout(0.2))\n",
    "CNN_model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "CNN_model.add(layers.Flatten())\n",
    "CNN_model.add(layers.Dense(128, activation='relu'))\n",
    "CNN_model.add(layers.Dropout(0.5))\n",
    "\n",
    "CNN_model.add(layers.Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "CNN_model.compile(optimzier=keras.optimizers.Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define low accuracy callback\n",
    "class LowAccuracy(keras.callbacks.Callback):\n",
    "    def __init__(self, threshold, patience):\n",
    "        super(LowAccuracy, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_accuracy = logs.get('val_accuracy', 0)\n",
    "        if val_accuracy < self.threshold:\n",
    "            self.counter += 1\n",
    "        if self.counter >= self.patience:\n",
    "            self.counter = 0\n",
    "            self.model.stop_training = True\n",
    "\n",
    "low_accuracy = LowAccuracy(threshold=0.02, patience=5)\n",
    "\n",
    "\n",
    "# Define model checkpoint callback\n",
    "checkpoint_path = './cnn-model/model_checkpoint.keras'\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Define a new plot callback\n",
    "plot_info_CNN = PlotInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_CNN = CNN_model.fit(datagen.flow(X_train_CNN, y_train_CNN, batch_size=32),\n",
    "                            epochs=50,\n",
    "                            class_weight=class_weights_dict,\n",
    "                            validation_data=datagen.flow(X_val_CNN, y_val_CNN, batch_size=32),\n",
    "                            callbacks=[early_stopping, model_checkpoint, plot_info_CNN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "y_pred_CNN = CNN_model.predict(X_test_CNN)\n",
    "test_loss, test_acc = CNN_model.evaluate(X_test_CNN, y_test_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert one-hot encoded y_pred_CNN back to label encoded form\n",
    "y_pred_CNN_label_encoded = np.argmax(y_pred_CNN, axis=1)\n",
    "\n",
    "# Extract unique classes present in the test dataset\n",
    "unique_classes_test_CNN = np.unique(y_test_CNN)\n",
    "\n",
    "# Convert encoded labels back to original classes\n",
    "target_classes_CNN = label_encoder.inverse_transform(unique_classes_test_CNN)\n",
    "\n",
    "# Generate confusion matrix\n",
    "confusion_m_CNN = confusion_matrix(y_test_CNN, y_pred_CNN_label_encoded)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(confusion_m_CNN, annot=True, fmt='d', cmap='Blues', xticklabels=target_classes_CNN, yticklabels=target_classes_CNN)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "report_CNN = classification_report(y_test_CNN, y_pred_CNN_label_encoded, target_names=target_classes_CNN, zero_division=1, output_dict=True)\n",
    "print(classification_report(y_test_CNN, y_pred_CNN_label_encoded, target_names=target_classes_CNN, zero_division=1))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
